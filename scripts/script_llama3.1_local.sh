python call_llm.py --model_name "llama3.1@8b" --use_prompt --output_path "./result/llama-local-prompt"