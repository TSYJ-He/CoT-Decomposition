python call_llm.py --model_name "llama3.1@8b" --output_path "./result/llama-local"
